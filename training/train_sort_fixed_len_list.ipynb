{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JeENCT8b1kAv"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMKKhcbR7B8VZnuM+CgWlil"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9b6164210cb4d2b8dbef5a91b1062d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_880c5e1ec4af4e09a295addce8782186",
              "IPY_MODEL_bdf4e852142b4aadb874cce4691464ee",
              "IPY_MODEL_190d2ccbc0cf4c7ab12614a91c54f005"
            ],
            "layout": "IPY_MODEL_096a0411c6684a588428c093333b7ef2"
          }
        },
        "880c5e1ec4af4e09a295addce8782186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_533124db4f3e43c3bdb52deb4756d107",
            "placeholder": "​",
            "style": "IPY_MODEL_bf1fc5a3368a4e02b852d4bc2289fbd3",
            "value": "100%"
          }
        },
        "bdf4e852142b4aadb874cce4691464ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51b056a81b23446ead88ce173c03c8e1",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31fe1285fc614447b5029030aba61691",
            "value": 10000
          }
        },
        "190d2ccbc0cf4c7ab12614a91c54f005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbd8eeb4d6a94d73851f53adeaea4800",
            "placeholder": "​",
            "style": "IPY_MODEL_bdd16112fbc74baeaeb3240ef4858869",
            "value": " 10000/10000 [01:39&lt;00:00, 202.65it/s]"
          }
        },
        "096a0411c6684a588428c093333b7ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "533124db4f3e43c3bdb52deb4756d107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf1fc5a3368a4e02b852d4bc2289fbd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51b056a81b23446ead88ce173c03c8e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31fe1285fc614447b5029030aba61691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cbd8eeb4d6a94d73851f53adeaea4800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdd16112fbc74baeaeb3240ef4858869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeENCT8b1kAv"
      },
      "source": [
        "# Setup\n",
        "(No need to read)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sxK_xiOO1kAv",
        "outputId": "8d699982-e7c3-4fef-fcf0-d513b1b31a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n",
            "  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-2kp2_mtn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-2kp2_mtn\n",
            "  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit 10d2f8a026d73eada861c7d51064f7e24d8f482c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer-lens==0.0.0)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n",
            "  Downloading datasets-2.14.3-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.1/519.1 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens==0.0.0)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer-lens==0.0.0)\n",
            "  Downloading jaxtyping-0.2.20-py3-none-any.whl (24 kB)\n",
            "Collecting numpy>=1.23 (from transformer-lens==0.0.0)\n",
            "  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.4.2)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.65.0)\n",
            "Collecting transformers>=4.25.1 (from transformer-lens==0.0.0)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb>=0.13.5 (from transformer-lens==0.0.0)\n",
            "  Downloading wandb-0.15.8-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.27.1)\n",
            "Collecting xxhash (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (6.0.1)\n",
            "Collecting typeguard>=2.13.3 (from jaxtyping>=0.2.11->transformer-lens==0.0.0)\n",
            "  Downloading typeguard-4.1.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (4.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2022.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.6)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading sentry_sdk-1.29.2-py2.py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.6/215.6 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: transformer-lens, pathtools\n",
            "  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=105856 sha256=8b8569bc6ad00f3b4d7748e92dcaec0688a67652fe6b37f8bea495ca076ad502\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x1o854xx/wheels/8a/1e/37/ffb9c15454a1725b13a9d9f5e74fb91725048884ad734b8c1f\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=5c7e639ecd9cccbd089889783329c5520d64e936c655fd59cb390a01de977f8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built transformer-lens pathtools\n",
            "Installing collected packages: tokenizers, safetensors, pathtools, xxhash, typeguard, smmap, setproctitle, sentry-sdk, numpy, fancy-einsum, einops, docker-pycreds, dill, beartype, multiprocess, jaxtyping, huggingface-hub, gitdb, transformers, GitPython, wandb, datasets, transformer-lens\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.25.2 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.32 beartype-0.14.1 datasets-2.14.3 dill-0.3.7 docker-pycreds-0.4.0 einops-0.6.1 fancy-einsum-0.0.3 gitdb-4.0.10 huggingface-hub-0.16.4 jaxtyping-0.2.20 multiprocess-0.70.15 numpy-1.25.2 pathtools-0.1.2 safetensors-0.3.1 sentry-sdk-1.29.2 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.13.3 transformer-lens-0.0.0 transformers-4.31.0 typeguard-4.1.0 wandb-0.15.8 xxhash-3.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## Installing the NodeSource Node.js 16.x repo...\n",
            "\n",
            "\n",
            "## Populating apt-get cache...\n",
            "\n",
            "+ apt-get update\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [43.3 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [850 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,235 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,103 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [21.7 kB]\n",
            "Fetched 3,612 kB in 4s (911 kB/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Confirming \"jammy\" is supported...\n",
            "\n",
            "+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/jammy/Release'\n",
            "\n",
            "## Adding the NodeSource signing key to your keyring...\n",
            "\n",
            "+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n",
            "\n",
            "## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n",
            "\n",
            "+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' > /etc/apt/sources.list.d/nodesource.list\n",
            "+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' >> /etc/apt/sources.list.d/nodesource.list\n",
            "\n",
            "## Running `apt-get update` for you...\n",
            "\n",
            "+ apt-get update\n",
            "Get:1 https://deb.nodesource.com/node_16.x jammy InRelease [4,583 B]\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:9 https://deb.nodesource.com/node_16.x jammy/main amd64 Packages [775 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 5,358 B in 3s (1,873 B/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n",
            "## You may also need development tools to build native addons:\n",
            "     sudo apt-get install gcc g++ make\n",
            "## To install the Yarn package manager, run:\n",
            "     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n",
            "     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n",
            "     sudo apt-get update && sudo apt-get install yarn\n",
            "\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 27.2 MB of archives.\n",
            "After this operation, 128 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_16.x jammy/main amd64 nodejs amd64 16.20.1-deb-1nodesource1 [27.2 MB]\n",
            "Fetched 27.2 MB in 1s (45.2 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 120511 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_16.20.1-deb-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (16.20.1-deb-1nodesource1) ...\n",
            "Setting up nodejs (16.20.1-deb-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting git+https://github.com/neelnanda-io/PySvelte.git\n",
            "  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-l83ieu0l\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-l83ieu0l\n",
            "  Resolved https://github.com/neelnanda-io/PySvelte.git to commit 6f5d971a148d40fb7481d400ae74551b37340e83\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (0.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.14.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (4.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (4.65.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (1.5.3)\n",
            "Collecting typeguard~=2.0 (from PySvelte==1.0.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (2.27.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PySvelte==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PySvelte==1.0.0) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->PySvelte==1.0.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->PySvelte==1.0.0) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (0.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->PySvelte==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->PySvelte==1.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->PySvelte==1.0.0) (1.3.0)\n",
            "Building wheels for collected packages: PySvelte\n",
            "  Building wheel for PySvelte (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PySvelte: filename=PySvelte-1.0.0-py3-none-any.whl size=158306 sha256=8f9e9703ee38b8441a43828b4937ad1693c36c5130778239694e51e0b353ab2f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-si63urme/wheels/fa/f6/f2/673ef7aeb78d7503b6e3e42387132822fdc38d3ee283d3e5b4\n",
            "Successfully built PySvelte\n",
            "Installing collected packages: typeguard, PySvelte\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.1.0\n",
            "    Uninstalling typeguard-4.1.0:\n",
            "      Successfully uninstalled typeguard-4.1.0\n",
            "Successfully installed PySvelte-1.0.0 typeguard-2.13.3\n",
            "Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.10/dist-packages (2.13.3)\n"
          ]
        }
      ],
      "source": [
        "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
        "DEBUG_MODE = False\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "    %pip install git+https://github.com/neelnanda-io/TransformerLens.git\n",
        "    # Install another version of node that makes PySvelte work way faster\n",
        "    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "    %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "    # Needed for PySvelte to work, v3 came out and broke things...\n",
        "    %pip install typeguard==2.13.3\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ucSutS0c1kAw"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEBUG_MODE:\n",
        "    # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"png\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uR_n0Mrl1kAx"
      },
      "outputs": [],
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import einops\n",
        "import tqdm.notebook as tqdm\n",
        "import random\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from jaxtyping import Float, Int\n",
        "from typing import List, Union, Optional\n",
        "from functools import partial\n",
        "import copy\n",
        "\n",
        "import itertools\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import dataclasses\n",
        "from dataclasses import dataclass\n",
        "import datasets\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YSZhMtBl1kAx"
      },
      "outputs": [],
      "source": [
        "import pysvelte\n",
        "\n",
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPzBb_kI1kAy"
      },
      "source": [
        "Plotting helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fBIDNqzV1kAy"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "update_layout_set = {\"xaxis_range\", \"yaxis_range\", \"hovermode\", \"xaxis_title\", \"yaxis_title\", \"colorbar\", \"colorscale\", \"coloraxis\", \"title_x\", \"bargap\", \"bargroupgap\", \"xaxis_tickformat\", \"yaxis_tickformat\", \"title_y\", \"legend_title_text\", \"xaxis_showgrid\", \"xaxis_gridwidth\", \"xaxis_gridcolor\", \"yaxis_showgrid\", \"yaxis_gridwidth\"}\n",
        "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    kwargs_post = {k: v for k, v in kwargs.items() if k in update_layout_set}\n",
        "    kwargs_pre = {k: v for k, v in kwargs.items() if k not in update_layout_set}\n",
        "    if \"facet_labels\" in kwargs_pre:\n",
        "        facet_labels = kwargs_pre.pop(\"facet_labels\")\n",
        "    else:\n",
        "        facet_labels = None\n",
        "    if \"color_continuous_scale\" not in kwargs_pre:\n",
        "        kwargs_pre[\"color_continuous_scale\"] = \"RdBu\"\n",
        "    fig = px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0,labels={\"x\":xaxis, \"y\":yaxis}, **kwargs_pre).update_layout(**kwargs_post)\n",
        "    if facet_labels:\n",
        "        for i, label in enumerate(facet_labels):\n",
        "            fig.layout.annotations[i]['text'] = label\n",
        "\n",
        "    fig.show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.line(y=utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)\n",
        "\n",
        "def lines(lines_list, x=None, mode='lines', labels=None, xaxis='', yaxis='', title = '', log_y=False, hover=None, **kwargs):\n",
        "    # Helper function to plot multiple lines\n",
        "    if type(lines_list)==torch.Tensor:\n",
        "        lines_list = [lines_list[i] for i in range(lines_list.shape[0])]\n",
        "    if x is None:\n",
        "        x=np.arange(len(lines_list[0]))\n",
        "    fig = go.Figure(layout={'title':title})\n",
        "    fig.update_xaxes(title=xaxis)\n",
        "    fig.update_yaxes(title=yaxis)\n",
        "    for c, line in enumerate(lines_list):\n",
        "        if type(line)==torch.Tensor:\n",
        "            line = utils.to_numpy(line)\n",
        "        if labels is not None:\n",
        "            label = labels[c]\n",
        "        else:\n",
        "            label = c\n",
        "        fig.add_trace(go.Scatter(x=x, y=line, mode=mode, name=label, hovertext=hover, **kwargs))\n",
        "    if log_y:\n",
        "        fig.update_layout(yaxis_type=\"log\")\n",
        "    fig.show()\n",
        "\n",
        "def bar(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.bar(\n",
        "        y=utils.to_numpy(tensor),\n",
        "        labels={\"x\": xaxis, \"y\": yaxis},\n",
        "        template=\"simple_white\",\n",
        "        **kwargs).show(renderer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformer_lens.patching as patching\n",
        "from transformer_lens import evals\n",
        "import math"
      ],
      "metadata": {
        "id": "MzEwzeib1tjE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_attn_patterns(heads, local_tokens, local_cache, title: str = \"\"):\n",
        "    labels = []\n",
        "    patterns = []\n",
        "    batch_index = 0\n",
        "\n",
        "    for head in heads:\n",
        "        if isinstance(head, tuple):\n",
        "            layer, head_index = head\n",
        "        else:\n",
        "            layer, head_index = head // model.cfg.n_heads, head % model.cfg.n_heads\n",
        "        patterns.append(local_cache[\"pattern\", layer][batch_index, head_index])\n",
        "        labels.append(f\"L{layer}H{head_index}\")\n",
        "    patterns = torch.stack(patterns, dim=-1)\n",
        "    attn_viz = pysvelte.AttentionMulti(tokens=model.to_str_tokens(local_tokens[batch_index]), attention=patterns, head_labels=labels)\n",
        "    display(HTML(f\"<h3>{title}</h3>\"))\n",
        "    attn_viz.show()"
      ],
      "metadata": {
        "id": "AgWNZo0c7sp3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model"
      ],
      "metadata": {
        "id": "HdPsT2ZOxeua"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "llysLeEq1kAy",
        "outputId": "71388036-25af-4f53-cbb5-71691a342ba1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7d4cadeb41f0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "torch.set_grad_enabled(True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "S0QibP7y7xCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40022779-3c13-4074-c35c-e161ed498d74"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LIST_LEN = 10\n",
        "MAX_NUM = 50\n",
        "cfg = HookedTransformerConfig(\n",
        "    n_layers=1,\n",
        "    d_model=128,\n",
        "    d_head=128,\n",
        "    n_ctx=LIST_LEN*2 + 2, # BOS 1 4 2 MID 1 2 4\n",
        "    d_vocab=MAX_NUM+2, # 0, 1, ..., MAX_NUM-1, BOS, MID\n",
        "    d_vocab_out=MAX_NUM,\n",
        "    attn_only=True,\n",
        "    normalization_type=None,\n",
        "    device=device,\n",
        "    seed=0\n",
        ")\n",
        "\n",
        "model = HookedTransformer(cfg)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "7SU1oTr-9Mq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a00769e2-5999-4d1b-f172-12cae6142bb6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HookedTransformer(\n",
            "  (embed): Embed()\n",
            "  (hook_embed): HookPoint()\n",
            "  (pos_embed): PosEmbed()\n",
            "  (hook_pos_embed): HookPoint()\n",
            "  (blocks): ModuleList(\n",
            "    (0): TransformerBlock(\n",
            "      (ln1): Identity()\n",
            "      (attn): Attention(\n",
            "        (hook_k): HookPoint()\n",
            "        (hook_q): HookPoint()\n",
            "        (hook_v): HookPoint()\n",
            "        (hook_z): HookPoint()\n",
            "        (hook_attn_scores): HookPoint()\n",
            "        (hook_pattern): HookPoint()\n",
            "        (hook_result): HookPoint()\n",
            "      )\n",
            "      (hook_q_input): HookPoint()\n",
            "      (hook_k_input): HookPoint()\n",
            "      (hook_v_input): HookPoint()\n",
            "      (hook_attn_out): HookPoint()\n",
            "      (hook_mlp_in): HookPoint()\n",
            "      (hook_mlp_out): HookPoint()\n",
            "      (hook_resid_pre): HookPoint()\n",
            "      (hook_resid_post): HookPoint()\n",
            "    )\n",
            "  )\n",
            "  (unembed): Unembed()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# disable biases\n",
        "for name, param in model.named_parameters():\n",
        "    if 'b_' in name:\n",
        "        param.requires_grad = False\n",
        "    print(name, param.shape, param.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPWJNjeyR80L",
        "outputId": "a57933e8-0480-44ad-81ac-d6ec6035cf1d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed.W_E torch.Size([52, 128]) True\n",
            "pos_embed.W_pos torch.Size([22, 128]) True\n",
            "blocks.0.attn.W_Q torch.Size([1, 128, 128]) True\n",
            "blocks.0.attn.W_K torch.Size([1, 128, 128]) True\n",
            "blocks.0.attn.W_V torch.Size([1, 128, 128]) True\n",
            "blocks.0.attn.W_O torch.Size([1, 128, 128]) True\n",
            "blocks.0.attn.b_Q torch.Size([1, 128]) False\n",
            "blocks.0.attn.b_K torch.Size([1, 128]) False\n",
            "blocks.0.attn.b_V torch.Size([1, 128]) False\n",
            "blocks.0.attn.b_O torch.Size([128]) False\n",
            "unembed.W_U torch.Size([128, 50]) True\n",
            "unembed.b_U torch.Size([50]) False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Code"
      ],
      "metadata": {
        "id": "hyLPtj4iUQ7C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task Dataset"
      ],
      "metadata": {
        "id": "D8vqK9UfSP2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_data_generator(cfg, batch_size, seed=0):\n",
        "    torch.manual_seed(seed)\n",
        "    MID_TOKEN = cfg.d_vocab-1\n",
        "    BOS_TOKEN = cfg.d_vocab-2\n",
        "    while True:\n",
        "        x = torch.randint(0, cfg.d_vocab_out, (batch_size, LIST_LEN))\n",
        "        sorted_x = x.sort(dim=-1).values\n",
        "        mid_vec = torch.ones(batch_size).unsqueeze(-1) * MID_TOKEN\n",
        "        bos_vec = torch.ones(batch_size).unsqueeze(-1) * BOS_TOKEN\n",
        "\n",
        "        tokens = torch.cat([bos_vec, x, mid_vec, sorted_x], dim=-1).to(torch.long)\n",
        "        yield tokens\n",
        "\n",
        "print(next(make_data_generator(cfg, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLVVL-94SNu-",
        "outputId": "516daf1c-e43b-4c83-c51e-fb4cbdfbb932"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50, 44, 39, 33, 10, 13, 29, 27,  3, 47, 33, 51,  3, 10, 13, 27, 29, 33,\n",
            "         33, 39, 44, 47],\n",
            "        [50,  1, 16,  6, 49, 28, 26,  6, 18, 44, 33, 51,  1,  6,  6, 16, 18, 26,\n",
            "         28, 33, 44, 49]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Fn"
      ],
      "metadata": {
        "id": "s22ky3jcUJYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(logits, tokens):\n",
        "    logits = logits[:, -(LIST_LEN+1):-1, :]\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    labels = tokens[:, -LIST_LEN:]\n",
        "    correct_log_probs = log_probs.gather(dim=-1, index=labels[..., None])[..., 0]\n",
        "    return -correct_log_probs.mean()\n",
        "\n",
        "with torch.no_grad():\n",
        "    tokens = next(make_data_generator(cfg, 2))\n",
        "    tokens = tokens.to(device)\n",
        "    logits = model(tokens)\n",
        "    loss = loss_fn(logits, tokens)\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EFCdCHOTp7B",
        "outputId": "d42a0238-6ed4-4681-94dd-f00853d4c848"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.9422, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"uniform loss:\", np.log(cfg.d_vocab_out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6-ZV1pzU9a5",
        "outputId": "656ac357-8d98-4bb1-e8ca-0f2a7bea0fdf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uniform loss: 3.912023005428146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup optimizer / dataloader"
      ],
      "metadata": {
        "id": "zPwPez1hXtYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "wd = 0.01\n",
        "betas = (0.9, 0.98)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd, betas=betas)\n",
        "\n",
        "batch_size = 256\n",
        "train_data_loader = make_data_generator(cfg, batch_size)"
      ],
      "metadata": {
        "id": "gY4qGOMaXv5I"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "7Acmvq77YAcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10000\n",
        "\n",
        "train_losses = []\n",
        "for epoch in tqdm.tqdm(range(num_epochs)):\n",
        "    tokens = next(train_data_loader)\n",
        "    tokens = tokens.to(device)\n",
        "\n",
        "    logits = model(tokens)\n",
        "    loss = loss_fn(logits, tokens)\n",
        "    loss.backward()\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch: {epoch}, train_loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f9b6164210cb4d2b8dbef5a91b1062d5",
            "880c5e1ec4af4e09a295addce8782186",
            "bdf4e852142b4aadb874cce4691464ee",
            "190d2ccbc0cf4c7ab12614a91c54f005",
            "096a0411c6684a588428c093333b7ef2",
            "533124db4f3e43c3bdb52deb4756d107",
            "bf1fc5a3368a4e02b852d4bc2289fbd3",
            "51b056a81b23446ead88ce173c03c8e1",
            "31fe1285fc614447b5029030aba61691",
            "cbd8eeb4d6a94d73851f53adeaea4800",
            "bdd16112fbc74baeaeb3240ef4858869"
          ]
        },
        "id": "qe0eyn8zX_3w",
        "outputId": "51566610-4a66-496c-b869-868971037c4e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9b6164210cb4d2b8dbef5a91b1062d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, train_loss: 3.9172489643096924\n",
            "Epoch: 100, train_loss: 2.3987338542938232\n",
            "Epoch: 200, train_loss: 1.2190136909484863\n",
            "Epoch: 300, train_loss: 0.4392028748989105\n",
            "Epoch: 400, train_loss: 0.3081232011318207\n",
            "Epoch: 500, train_loss: 0.22951793670654297\n",
            "Epoch: 600, train_loss: 0.17295096814632416\n",
            "Epoch: 700, train_loss: 0.16446828842163086\n",
            "Epoch: 800, train_loss: 0.1401982307434082\n",
            "Epoch: 900, train_loss: 0.15263152122497559\n",
            "Epoch: 1000, train_loss: 0.1349060982465744\n",
            "Epoch: 1100, train_loss: 0.13596658408641815\n",
            "Epoch: 1200, train_loss: 0.12159226089715958\n",
            "Epoch: 1300, train_loss: 0.10960417985916138\n",
            "Epoch: 1400, train_loss: 0.1079125627875328\n",
            "Epoch: 1500, train_loss: 0.09948201477527618\n",
            "Epoch: 1600, train_loss: 0.10766289383172989\n",
            "Epoch: 1700, train_loss: 0.10108118504285812\n",
            "Epoch: 1800, train_loss: 0.12263192981481552\n",
            "Epoch: 1900, train_loss: 0.10367965698242188\n",
            "Epoch: 2000, train_loss: 0.11788195371627808\n",
            "Epoch: 2100, train_loss: 0.10300252586603165\n",
            "Epoch: 2200, train_loss: 0.10170023888349533\n",
            "Epoch: 2300, train_loss: 0.11112874001264572\n",
            "Epoch: 2400, train_loss: 0.0907863900065422\n",
            "Epoch: 2500, train_loss: 0.08786841481924057\n",
            "Epoch: 2600, train_loss: 0.08017747849225998\n",
            "Epoch: 2700, train_loss: 0.08198552578687668\n",
            "Epoch: 2800, train_loss: 0.08011473715305328\n",
            "Epoch: 2900, train_loss: 0.08798092603683472\n",
            "Epoch: 3000, train_loss: 0.08739271014928818\n",
            "Epoch: 3100, train_loss: 0.07409738749265671\n",
            "Epoch: 3200, train_loss: 0.08091635257005692\n",
            "Epoch: 3300, train_loss: 0.0717572569847107\n",
            "Epoch: 3400, train_loss: 0.06810206174850464\n",
            "Epoch: 3500, train_loss: 0.08440282195806503\n",
            "Epoch: 3600, train_loss: 0.08790038526058197\n",
            "Epoch: 3700, train_loss: 0.055397678166627884\n",
            "Epoch: 3800, train_loss: 0.07220838218927383\n",
            "Epoch: 3900, train_loss: 0.06892742216587067\n",
            "Epoch: 4000, train_loss: 0.0526638999581337\n",
            "Epoch: 4100, train_loss: 0.0504130981862545\n",
            "Epoch: 4200, train_loss: 0.04701066389679909\n",
            "Epoch: 4300, train_loss: 0.052835848182439804\n",
            "Epoch: 4400, train_loss: 0.06106376275420189\n",
            "Epoch: 4500, train_loss: 0.03967764601111412\n",
            "Epoch: 4600, train_loss: 0.045637935400009155\n",
            "Epoch: 4700, train_loss: 0.049423377960920334\n",
            "Epoch: 4800, train_loss: 0.04103114828467369\n",
            "Epoch: 4900, train_loss: 0.032530318945646286\n",
            "Epoch: 5000, train_loss: 0.03604692593216896\n",
            "Epoch: 5100, train_loss: 0.06109661981463432\n",
            "Epoch: 5200, train_loss: 0.0378643237054348\n",
            "Epoch: 5300, train_loss: 0.04218633100390434\n",
            "Epoch: 5400, train_loss: 0.031152626499533653\n",
            "Epoch: 5500, train_loss: 0.03396552428603172\n",
            "Epoch: 5600, train_loss: 0.03239196166396141\n",
            "Epoch: 5700, train_loss: 0.032644085586071014\n",
            "Epoch: 5800, train_loss: 0.02709365449845791\n",
            "Epoch: 5900, train_loss: 0.030244488269090652\n",
            "Epoch: 6000, train_loss: 0.02423373982310295\n",
            "Epoch: 6100, train_loss: 0.028905997052788734\n",
            "Epoch: 6200, train_loss: 0.03310428187251091\n",
            "Epoch: 6300, train_loss: 0.028574390336871147\n",
            "Epoch: 6400, train_loss: 0.028557265177369118\n",
            "Epoch: 6500, train_loss: 0.01827961578965187\n",
            "Epoch: 6600, train_loss: 0.021913843229413033\n",
            "Epoch: 6700, train_loss: 0.01934007555246353\n",
            "Epoch: 6800, train_loss: 0.020978886634111404\n",
            "Epoch: 6900, train_loss: 0.019298946484923363\n",
            "Epoch: 7000, train_loss: 0.021241968497633934\n",
            "Epoch: 7100, train_loss: 0.017755260691046715\n",
            "Epoch: 7200, train_loss: 0.022762490436434746\n",
            "Epoch: 7300, train_loss: 0.023663707077503204\n",
            "Epoch: 7400, train_loss: 0.02515055052936077\n",
            "Epoch: 7500, train_loss: 0.022726798430085182\n",
            "Epoch: 7600, train_loss: 0.02688748575747013\n",
            "Epoch: 7700, train_loss: 0.02478068694472313\n",
            "Epoch: 7800, train_loss: 0.023699790239334106\n",
            "Epoch: 7900, train_loss: 0.024109184741973877\n",
            "Epoch: 8000, train_loss: 0.02274169772863388\n",
            "Epoch: 8100, train_loss: 0.01647796295583248\n",
            "Epoch: 8200, train_loss: 0.019342049956321716\n",
            "Epoch: 8300, train_loss: 0.015897247940301895\n",
            "Epoch: 8400, train_loss: 0.025213463231921196\n",
            "Epoch: 8500, train_loss: 0.016112128272652626\n",
            "Epoch: 8600, train_loss: 0.04325265809893608\n",
            "Epoch: 8700, train_loss: 0.024800710380077362\n",
            "Epoch: 8800, train_loss: 0.032085344195365906\n",
            "Epoch: 8900, train_loss: 0.009468602947890759\n",
            "Epoch: 9000, train_loss: 0.04632440209388733\n",
            "Epoch: 9100, train_loss: 0.018265971913933754\n",
            "Epoch: 9200, train_loss: 0.03141786530613899\n",
            "Epoch: 9300, train_loss: 0.016125719994306564\n",
            "Epoch: 9400, train_loss: 0.024192942306399345\n",
            "Epoch: 9500, train_loss: 0.01101586502045393\n",
            "Epoch: 9600, train_loss: 0.013714306056499481\n",
            "Epoch: 9700, train_loss: 0.013964948244392872\n",
            "Epoch: 9800, train_loss: 0.01364861149340868\n",
            "Epoch: 9900, train_loss: 0.013939127326011658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity check"
      ],
      "metadata": {
        "id": "k1Nv_thKYdHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = next(train_data_loader).to(device)\n",
        "with torch.inference_mode():\n",
        "    logits = model(test_data)\n",
        "    logits = logits[:, -(LIST_LEN+1):-1, :]\n",
        "    preds = logits.argmax(dim=-1)\n",
        "    labels = test_data[:, -LIST_LEN:]\n",
        "    acc = (preds == labels).float().mean()\n",
        "    print(\"accuracy on test sample:\", acc.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxUV0NSmYUib",
        "outputId": "66929204-43e2-4476-b828-ee66db790b54"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on test sample: 0.9957031607627869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model"
      ],
      "metadata": {
        "id": "qj_yVXmvLyYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir ../models"
      ],
      "metadata": {
        "id": "vOd8urq4L22P"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"../models/sort_fixed_len_list_model.pt\"\n",
        "torch.save(model.state_dict(), filename)"
      ],
      "metadata": {
        "id": "dCbo4XMyL0GZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check we can load model\n",
        "\n",
        "LIST_LEN = 10\n",
        "MAX_NUM = 50\n",
        "cfg = HookedTransformerConfig(\n",
        "    n_layers=1,\n",
        "    d_model=128,\n",
        "    d_head=128,\n",
        "    n_ctx=LIST_LEN*2 + 2, # BOS 1 4 2 MID 1 2 4\n",
        "    d_vocab=MAX_NUM+2, # 0, 1, ..., MAX_NUM-1, BOS, MID\n",
        "    d_vocab_out=MAX_NUM,\n",
        "    attn_only=True,\n",
        "    normalization_type=None,\n",
        "    device=device,\n",
        "    seed=0\n",
        ")\n",
        "\n",
        "loaded_model = HookedTransformer(cfg)\n",
        "\n",
        "state_dict = torch.load(filename)\n",
        "loaded_model.load_state_dict(state_dict, strict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFZGiU-mMGX0",
        "outputId": "d7acc1db-32d0-45f3-b771-0c9a8ec6f8c0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}