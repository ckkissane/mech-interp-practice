{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "JeENCT8b1kAv"
      ],
      "authorship_tag": "ABX9TyNmMH38mThDULpCTq7btmgD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem"
      ],
      "metadata": {
        "id": "T_imxxzz2h63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reverse engineer how a 1L attn-only transformer solves the [majority element](https://leetcode.com/problems/majority-element/) problem."
      ],
      "metadata": {
        "id": "Un73Tjrp2j24"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeENCT8b1kAv"
      },
      "source": [
        "# Setup\n",
        "(No need to read)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ckkissane/mech-interp-practice.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE5ny4We6xcf",
        "outputId": "210e4fd4-345a-454b-91d7-eb1ec69d12d2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mech-interp-practice'...\n",
            "remote: Enumerating objects: 319, done.\u001b[K\n",
            "remote: Counting objects: 100% (138/138), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 319 (delta 79), reused 32 (delta 14), pack-reused 181\u001b[K\n",
            "Receiving objects: 100% (319/319), 38.61 MiB | 10.19 MiB/s, done.\n",
            "Resolving deltas: 100% (158/158), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sxK_xiOO1kAv",
        "outputId": "160877e5-76f3-492c-b949-308952163845",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n",
            "  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-q3by3v39\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-q3by3v39\n",
            "  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit 54d548de4995a1ecc5b01b9c03aceaf0966c0eb3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer-lens==0.0.0)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens==0.0.0)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer-lens==0.0.0)\n",
            "  Downloading jaxtyping-0.2.21-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.5.2)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.66.1)\n",
            "Collecting transformers>=4.25.1 (from transformer-lens==0.0.0)\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb>=0.13.5 (from transformer-lens==0.0.0)\n",
            "  Downloading wandb-0.15.9-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n",
            "Collecting xxhash (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (6.0.1)\n",
            "Collecting typeguard>=2.13.3 (from jaxtyping>=0.2.11->transformer-lens==0.0.0)\n",
            "  Downloading typeguard-4.1.3-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (4.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading sentry_sdk-1.30.0-py2.py3-none-any.whl (218 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.8/218.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: transformer-lens, pathtools\n",
            "  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=105997 sha256=a4f63d11481e6cdbba8e4606bf3e6e5062eff3a216a21ddfe9e8dc80982137cc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6z63z6gv/wheels/8a/1e/37/ffb9c15454a1725b13a9d9f5e74fb91725048884ad734b8c1f\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=9b81759664007bab782af7f98e1c538edce39ce8326e313f67ffac28b04c91b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built transformer-lens pathtools\n",
            "Installing collected packages: tokenizers, safetensors, pathtools, xxhash, typeguard, smmap, setproctitle, sentry-sdk, fancy-einsum, einops, docker-pycreds, dill, beartype, multiprocess, jaxtyping, huggingface-hub, gitdb, transformers, GitPython, wandb, datasets, transformer-lens\n",
            "Successfully installed GitPython-3.1.32 beartype-0.14.1 datasets-2.14.4 dill-0.3.7 docker-pycreds-0.4.0 einops-0.6.1 fancy-einsum-0.0.3 gitdb-4.0.10 huggingface-hub-0.16.4 jaxtyping-0.2.21 multiprocess-0.70.15 pathtools-0.1.2 safetensors-0.3.3 sentry-sdk-1.30.0 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.13.3 transformer-lens-0.0.0 transformers-4.32.1 typeguard-4.1.3 wandb-0.15.9 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
        "DEBUG_MODE = False\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "    %pip install git+https://github.com/neelnanda-io/TransformerLens.git\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    %pip install git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
        "except:\n",
        "    import os; os.environ[\"ACCELERATE_DISABLE_RICH\"] = \"1\"\n",
        "    from IPython import get_ipython\n",
        "    ipython = get_ipython()\n",
        "    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
        "    ipython.run_line_magic(\"autoreload\", \"2\")"
      ],
      "metadata": {
        "id": "zfSn5iNSFKlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8374daff-8e08-4c7f-ca27-6a3b3e109ac1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
            "  Cloning https://github.com/callummcdougall/CircuitsVis.git to /tmp/pip-req-build-5e2524s2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/callummcdougall/CircuitsVis.git /tmp/pip-req-build-5e2524s2\n",
            "  Resolved https://github.com/callummcdougall/CircuitsVis.git to commit 5afe6fed827592dd525490b81e213bc3e2241a4a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting importlib-metadata<6.0.0,>=5.1.0 (from circuitsvis==0.0.0)\n",
            "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from circuitsvis==0.0.0) (1.23.5)\n",
            "Requirement already satisfied: torch<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis==0.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis==0.0.0) (3.16.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<3.0,>=2.0->circuitsvis==0.0.0) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<3.0,>=2.0->circuitsvis==0.0.0) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0,>=2.0->circuitsvis==0.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0,>=2.0->circuitsvis==0.0.0) (1.3.0)\n",
            "Building wheels for collected packages: circuitsvis\n",
            "  Building wheel for circuitsvis (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for circuitsvis: filename=circuitsvis-0.0.0-py3-none-any.whl size=6170635 sha256=18416d046391a417a819352fdc50227fc53f6bd4b4a79fa57c3ef379f1518948\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6azqk56r/wheels/86/be/ad/78078aba9344d200aad61b63d35cdaecdec160212f039eed74\n",
            "Successfully built circuitsvis\n",
            "Installing collected packages: importlib-metadata, circuitsvis\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.8.0\n",
            "    Uninstalling importlib-metadata-6.8.0:\n",
            "      Successfully uninstalled importlib-metadata-6.8.0\n",
            "Successfully installed circuitsvis-0.0.0 importlib-metadata-5.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ucSutS0c1kAw"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEBUG_MODE:\n",
        "    # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"png\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uR_n0Mrl1kAx"
      },
      "outputs": [],
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import circuitsvis as cv\n",
        "import einops\n",
        "import tqdm.notebook as tqdm\n",
        "import random\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from jaxtyping import Float, Int\n",
        "from typing import List, Union, Optional\n",
        "from functools import partial\n",
        "import copy\n",
        "\n",
        "import itertools\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import dataclasses\n",
        "from dataclasses import dataclass\n",
        "import datasets\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YSZhMtBl1kAx"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPzBb_kI1kAy"
      },
      "source": [
        "Plotting helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fBIDNqzV1kAy"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "update_layout_set = {\"xaxis_range\", \"yaxis_range\", \"hovermode\", \"xaxis_title\", \"yaxis_title\", \"colorbar\", \"colorscale\", \"coloraxis\", \"title_x\", \"bargap\", \"bargroupgap\", \"xaxis_tickformat\", \"yaxis_tickformat\", \"title_y\", \"legend_title_text\", \"xaxis_showgrid\", \"xaxis_gridwidth\", \"xaxis_gridcolor\", \"yaxis_showgrid\", \"yaxis_gridwidth\"}\n",
        "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    if isinstance(tensor, list):\n",
        "        tensor = torch.stack(tensor)\n",
        "    kwargs_post = {k: v for k, v in kwargs.items() if k in update_layout_set}\n",
        "    kwargs_pre = {k: v for k, v in kwargs.items() if k not in update_layout_set}\n",
        "    if \"facet_labels\" in kwargs_pre:\n",
        "        facet_labels = kwargs_pre.pop(\"facet_labels\")\n",
        "    else:\n",
        "        facet_labels = None\n",
        "    if \"color_continuous_scale\" not in kwargs_pre:\n",
        "        kwargs_pre[\"color_continuous_scale\"] = \"RdBu\"\n",
        "    fig = px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0,labels={\"x\":xaxis, \"y\":yaxis}, **kwargs_pre).update_layout(**kwargs_post)\n",
        "    if facet_labels:\n",
        "        for i, label in enumerate(facet_labels):\n",
        "            fig.layout.annotations[i]['text'] = label\n",
        "\n",
        "    fig.show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.line(y=utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)\n",
        "\n",
        "def lines(lines_list, x=None, mode='lines', labels=None, xaxis='', yaxis='', title = '', log_y=False, hover=None, **kwargs):\n",
        "    # Helper function to plot multiple lines\n",
        "    if type(lines_list)==torch.Tensor:\n",
        "        lines_list = [lines_list[i] for i in range(lines_list.shape[0])]\n",
        "    if x is None:\n",
        "        x=np.arange(len(lines_list[0]))\n",
        "    fig = go.Figure(layout={'title':title})\n",
        "    fig.update_xaxes(title=xaxis)\n",
        "    fig.update_yaxes(title=yaxis)\n",
        "    for c, line in enumerate(lines_list):\n",
        "        if type(line)==torch.Tensor:\n",
        "            line = utils.to_numpy(line)\n",
        "        if labels is not None:\n",
        "            label = labels[c]\n",
        "        else:\n",
        "            label = c\n",
        "        fig.add_trace(go.Scatter(x=x, y=line, mode=mode, name=label, hovertext=hover, **kwargs))\n",
        "    if log_y:\n",
        "        fig.update_layout(yaxis_type=\"log\")\n",
        "    fig.show()\n",
        "\n",
        "def bar(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.bar(\n",
        "        y=utils.to_numpy(tensor),\n",
        "        labels={\"x\": xaxis, \"y\": yaxis},\n",
        "        template=\"simple_white\",\n",
        "        **kwargs).show(renderer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformer_lens.patching as patching\n",
        "from transformer_lens import evals\n",
        "import math"
      ],
      "metadata": {
        "id": "MzEwzeib1tjE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def disable_biases(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'b_' in name:\n",
        "            param.requires_grad = False\n",
        "\n",
        "def disable_pos_embed(model):\n",
        "    assert model.cfg.positional_embedding_type == \"standard\"\n",
        "    model.pos_embed.W_pos = nn.Parameter(torch.zeros_like(model.pos_embed.W_pos))\n",
        "    model.pos_embed.W_pos.requires_grad = False"
      ],
      "metadata": {
        "id": "umLRJ7qyrDKt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model"
      ],
      "metadata": {
        "id": "HdPsT2ZOxeua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is a 1L, 1H, attn-only transformer with no biases, layernorms, or positional embeddings. Note this is an extremely tiny model, yet was able to perform very well on this task. I've already trained the model, so below I just load it to this colab notebook:"
      ],
      "metadata": {
        "id": "mBBHjlIg4g1G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "llysLeEq1kAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7dd640b-3900-4eea-dc31-6a8a1d5823a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x79d829b16290>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "torch.set_grad_enabled(False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "S0QibP7y7xCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901f49ab-5dfa-4eb9-c45b-610585562e7e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_ELT = 50\n",
        "LIST_LEN = 10\n",
        "cfg = HookedTransformerConfig(\n",
        "    n_layers=1,\n",
        "    d_model=64,\n",
        "    attn_only=True,\n",
        "    d_head=64,\n",
        "    n_heads=1,\n",
        "    normalization_type=None,\n",
        "    d_vocab=MAX_ELT+2, # 0, ..., MAX_ELT-1, BOS, END\n",
        "    n_ctx=LIST_LEN+2, #BOS a1 ... an END\n",
        "    device=device,\n",
        "    seed=0\n",
        ")\n",
        "\n",
        "model = HookedTransformer(cfg)"
      ],
      "metadata": {
        "id": "7SU1oTr-9Mq3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_dir = \"mech-interp-practice/models/\"\n",
        "filename = models_dir + \"majority_element_model.pt\"\n",
        "\n",
        "state_dict = torch.load(filename)\n",
        "model.load_state_dict(state_dict, strict=False);"
      ],
      "metadata": {
        "id": "KUBo1PZe43Cx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task description"
      ],
      "metadata": {
        "id": "2T_qHdqg3LnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall the leetcode description: \"Given an array nums of size n, return the majority element. The majority element is the element that appears more than $\\lfloor n/2 \\rfloor$ times. You may assume that the majority element always exists in the array”\n",
        "\n",
        "\n",
        "The models inputs are always of the form:\n",
        "\n",
        "\n",
        "[BOS, a1, a2, ..., a10, END]\n",
        "\n",
        "\n",
        "Where BOS (51) and END (50) are special tokens at the start and end of every sequence. a1, ..., a10 are the array elements, which range between [0, 49] inclusive. Note that I fixed n=10 for every example during training. The model was trained to always output its prediction for the majority element at the END position.\n",
        "\n",
        "\n",
        "Each example has a corresponding target, which is the majority element for that example. Below I provide the same data loader used in training, and some tokens / targets that you can use to start investigating the model:\n"
      ],
      "metadata": {
        "id": "eL2Sn2mE3N32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_data_generator(cfg, batch_size, seed=0):\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    BOS_TOKEN=cfg.d_vocab-1\n",
        "    END_TOKEN=cfg.d_vocab-2\n",
        "    bos_vec = torch.full((batch_size, 1), BOS_TOKEN)\n",
        "    end_vec = torch.full((batch_size, 1), END_TOKEN)\n",
        "    majority_num = LIST_LEN // 2 + 1\n",
        "    while True:\n",
        "        x = torch.randint(0, MAX_ELT, (batch_size, LIST_LEN))\n",
        "        majority_elt = random.randint(0, MAX_ELT-1)\n",
        "        majority_indices = torch.randperm(LIST_LEN)[:majority_num]\n",
        "        x[:, majority_indices] = majority_elt\n",
        "        yield torch.cat([bos_vec, x, end_vec], dim=-1), torch.full((batch_size,), majority_elt)\n",
        "\n",
        "batch_size = 256\n",
        "data_loader = make_data_generator(cfg, batch_size, seed=42)\n",
        "\n",
        "tokens, targets = next(data_loader)\n",
        "tokens, targets = tokens.to(device), targets.to(device)\n",
        "print(\"tokens:\", tokens.shape)\n",
        "print(tokens[:5])\n",
        "print(\"targets:\", targets.shape)\n",
        "print(targets[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KdShxgm4FAy",
        "outputId": "57ce0f24-4f7c-49a7-e7a3-393b4e34d56f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens: torch.Size([256, 12])\n",
            "tensor([[51, 40, 40, 40, 40, 26, 40, 20, 40,  0, 13, 50],\n",
            "        [51, 40, 40, 40, 40, 31, 40, 15, 40, 17,  6, 50],\n",
            "        [51, 40, 40, 40, 40, 49, 40, 41, 40, 37, 19, 50],\n",
            "        [51, 40, 40, 40, 40, 33, 40, 39, 40, 32, 10, 50],\n",
            "        [51, 40, 40, 40, 40,  7, 40, 43, 40, 43, 27, 50]], device='cuda:0')\n",
            "targets: torch.Size([256])\n",
            "tensor([40, 40, 40, 40, 40], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'll also provide the loss function used for training:"
      ],
      "metadata": {
        "id": "v5njmnzOCiMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(logits, labels, per_token=False):\n",
        "    if logits.ndim==3:\n",
        "        logits=logits[:, -1, :]\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    correct_log_probs = log_probs.gather(dim=-1, index=labels[..., None])[..., 0]\n",
        "    if per_token:\n",
        "        return -correct_log_probs\n",
        "    else:\n",
        "        return -correct_log_probs.mean()"
      ],
      "metadata": {
        "id": "dluS452ECm4y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be useful to convert tokens to a list of strings for plotly / CircuitsVis labels. Here is a function that you can optionally use for this:"
      ],
      "metadata": {
        "id": "LRzV16SZE3m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_labels(tokens):\n",
        "    if tokens.ndim == 2:\n",
        "        tokens = tokens[0]\n",
        "    res = [f\"{tok}_{i}\" for i, tok in enumerate(tokens)]\n",
        "    res[0] = \"BOS\"\n",
        "    res[-1] = \"END\"\n",
        "    return res\n",
        "\n",
        "print(tokens_to_labels(tokens))"
      ],
      "metadata": {
        "id": "eUm6nsmOE31Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad75b329-d87e-4045-9c07-e84f99e34fb3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BOS', '40_1', '40_2', '40_3', '40_4', '26_5', '40_6', '20_7', '40_8', '0_9', '13_10', 'END']\n"
          ]
        }
      ]
    }
  ]
}